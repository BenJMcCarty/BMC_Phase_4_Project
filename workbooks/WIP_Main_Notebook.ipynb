{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Guiding question:** What are the top 5 zip codes based on the ROI for the cit of Pittsburgh?\n",
    ">\n",
    ">\n",
    "> **Evaluation Metric:** ROI/Risk\n",
    ">\n",
    ">\n",
    "> **Dataset:** Zillow data from 1996-2018\n",
    ">\n",
    ">\n",
    "> **Goal:** time series modeling for each zip code to calculate forecasted sale prices.\n",
    ">\n",
    ">\n",
    "> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Workflow: Start -> Finish**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T20:13:49.202652Z",
     "start_time": "2021-08-25T20:13:49.094652Z"
    }
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "## Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.tsa.api as tsa\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import pmdarima as pmd\n",
    "from pmdarima.arima import ndiffs\n",
    "from pmdarima.arima import nsdiffs\n",
    "\n",
    "## Settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']=(18,8)\n",
    "plt.style.use('seaborn-talk')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "pd.set_option('max_rows', 100)\n",
    "\n",
    "from bmc_functions import eda, time_series_modeling\n",
    "from bmc_functions import time_series_modeling as tsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:22.473718Z",
     "start_time": "2021-08-25T19:43:22.368562Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:26.242530Z",
     "start_time": "2021-08-25T19:43:22.477693Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Reading data\n",
    "source = '../data/zillow_data.csv'\n",
    "data = pd.read_csv(source)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:26.352532Z",
     "start_time": "2021-08-25T19:43:26.245503Z"
    }
   },
   "outputs": [],
   "source": [
    "## Initial inspection\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Subset of Zipcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The dataset is much larger than I need for my purposes, so I will select only the zip codes for the Pittsburgh Metro area.\n",
    ">\n",
    ">\n",
    "> To select this data, I will filter the initial dataframe by selecting \"Pittsburgh\" from the \"city\" column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:26.648501Z",
     "start_time": "2021-08-25T19:43:26.355502Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Selecting the city of Pittsburgh \n",
    "\n",
    "pitt_df = data[data['City'] == 'Pittsburgh']\n",
    "pitt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:27.560538Z",
     "start_time": "2021-08-25T19:43:26.650501Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Examining statistics for the new dataframe\n",
    "eda.report_df(pitt_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:27.656537Z",
     "start_time": "2021-08-25T19:43:27.562554Z"
    }
   },
   "outputs": [],
   "source": [
    "def melt_data(df):\n",
    "    \"\"\"\n",
    "    Takes the zillow_data dataset in wide form or a subset of the zillow_dataset.  \n",
    "    Returns a long-form datetime dataframe with the datetime column names\n",
    "    as the index and the values as the 'values' column.\n",
    "    \n",
    "    If more than one row is passes in the wide-form dataset, the values column\n",
    "    will be the mean of the values from the datetime columns in all of the rows.\n",
    "    \"\"\"\n",
    "    \n",
    "    melted = pd.melt(df, id_vars=['RegionName', 'RegionID', 'SizeRank',\n",
    "                                  'City', 'State', 'Metro', 'CountyName'],\n",
    "                     var_name='time')\n",
    "    melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "    melted = melted.dropna(subset=['value'])\n",
    "    return melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:27.781649Z",
     "start_time": "2021-08-25T19:43:27.659550Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Melting the dataframe to move the dates from columns into a new row per zipcode\n",
    "pitt_melted = melt_data(pitt_df)\n",
    "pitt_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:27.889540Z",
     "start_time": "2021-08-25T19:43:27.783535Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirming conversion to \"datetime\" datatype\n",
    "pitt_melted['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:28.000505Z",
     "start_time": "2021-08-25T19:43:27.892506Z"
    }
   },
   "outputs": [],
   "source": [
    "## Selecting columns to keep for modeling\n",
    "keep = ['RegionName', 'time', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:28.126535Z",
     "start_time": "2021-08-25T19:43:28.003509Z"
    }
   },
   "outputs": [],
   "source": [
    "pitt_data = pitt_melted[keep]\n",
    "pitt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:28.250543Z",
     "start_time": "2021-08-25T19:43:28.129508Z"
    }
   },
   "outputs": [],
   "source": [
    "pitt_data.set_index('time', inplace=True)\n",
    "pitt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **The following code is adapted from code within [this notebook](https://github.com/flatiron-school/Online-DS-FT-022221-Cohort-Notes/blob/master/Phase_4/topic_37_intro_to_time_series/topic_37_intro_to_time_series_crime_v3-SG.ipynb) by James Irving, Ph.D.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:28.358507Z",
     "start_time": "2021-08-25T19:43:28.252506Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating list of unique zipcodes from the dataframe\n",
    "zipcodes = list(pitt_data['RegionName'].unique())\n",
    "zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:28.467506Z",
     "start_time": "2021-08-25T19:43:28.360509Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting first zipcode in list - datetime index and associated sell value\n",
    "test_code = zipcodes[0]\n",
    "test_zipcode_series = pitt_data.groupby('RegionName')\\\n",
    "                                .get_group(test_code)['value']\\\n",
    "                                                            .rename(test_code)\n",
    "test_zipcode_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:28.747541Z",
     "start_time": "2021-08-25T19:43:28.470507Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating a dictionary to store each zipcode and its timeseries data\n",
    "\n",
    "zipcodes_dict = {}\n",
    "\n",
    "for zipcode in zipcodes:\n",
    "    \n",
    "    ## Create the series for each zipcode\n",
    "    zipcode_series = pitt_data.groupby('RegionName')\\\n",
    "                                                .get_group(zipcode)['value']\\\n",
    "                                                            .rename(zipcode)\n",
    "    \n",
    "    ## Save in zipcode dictionary\n",
    "    zipcodes_dict[zipcode] = zipcode_series.resample('MS').asfreq()\n",
    "    \n",
    "## Display the keys\n",
    "zipcodes_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:28.856537Z",
     "start_time": "2021-08-25T19:43:28.749510Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirming all zip codes are present in dictionary\n",
    "list(zipcodes_dict.keys()) == zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:28.966541Z",
     "start_time": "2021-08-25T19:43:28.858507Z"
    }
   },
   "outputs": [],
   "source": [
    "zipcodes_dict[15206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:29.092539Z",
     "start_time": "2021-08-25T19:43:28.968507Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zipcodes_df_full = pd.DataFrame(zipcodes_dict)\n",
    "zipcodes_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:29.216507Z",
     "start_time": "2021-08-25T19:43:29.094508Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zipcodes_df = zipcodes_df_full.loc['2008':]\n",
    "zipcodes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T/T Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:29.338509Z",
     "start_time": "2021-08-25T19:43:29.218532Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Testing first zipcode from dictionary\n",
    "zipcode_val = zipcodes_df[15206].copy()\n",
    "zipcode_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:29.760542Z",
     "start_time": "2021-08-25T19:43:29.340530Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plotting first zipcode to test\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = zipcode_val.plot()\n",
    "ax.legend()\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Price ($)')\n",
    "ax.set_title(f'Train/Test Split for Zipcode {zipcode_val.name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:29.869543Z",
     "start_time": "2021-08-25T19:43:29.762527Z"
    }
   },
   "outputs": [],
   "source": [
    "zipcodes_df[15206].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:29.994510Z",
     "start_time": "2021-08-25T19:43:29.873512Z"
    }
   },
   "outputs": [],
   "source": [
    "round(zipcodes_df[15206].shape[0]*.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:30.104543Z",
     "start_time": "2021-08-25T19:43:29.998511Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Creating a function to streamline plotting all of the zipcodes\n",
    "\n",
    "# def ts_split(timeseries_df, threshold):\n",
    "#     tts_cutoff = round(timeseries_df.shape[0]*threshold)\n",
    "#     train = timeseries_df.iloc[:tts_cutoff]\n",
    "#     test = timeseries_df.iloc[tts_cutoff:]\n",
    "\n",
    "#     ## Plot\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax = train.plot(label='Train')\n",
    "#     ax = test.plot(label='Test')\n",
    "#     ax.legend()\n",
    "#     ax.set_xlabel('Years')\n",
    "#     ax.set_ylabel('Price ($)')\n",
    "#     ax.set_title(f'Train/Test Split for Zipcode {timeseries_df.name}')\n",
    "#     ax.axvline(train.index[-1], linestyle=\":\")\n",
    "#     plt.show();\n",
    "    \n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:57:38.279513Z",
     "start_time": "2021-08-25T19:57:37.907480Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Creating train/test split for first zipcode\n",
    "train, test = tsm.ts_split(zipcode_val, show_vis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:30.622512Z",
     "start_time": "2021-08-25T19:43:30.516528Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting training set\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:30.731544Z",
     "start_time": "2021-08-25T19:43:30.624515Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Inspecting testing set\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:30.839554Z",
     "start_time": "2021-08-25T19:43:30.732560Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The following functions are adapted from [this notebook](https://github.com/flatiron-school/Online-DS-FT-022221-Cohort-Notes/blob/master/Phase_4/topic_37_intro_to_time_series/topic_37_intro_to_time_series_crime_v3-SG.ipynb) by James Irving, Ph.D.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dickey Fuller Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:30.949514Z",
     "start_time": "2021-08-25T19:43:30.841513Z"
    }
   },
   "outputs": [],
   "source": [
    "## Performing Dickey-Fuller Test\n",
    "zipdf_results = tsa.stattools.adfuller(train)\n",
    "zipdf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:31.074514Z",
     "start_time": "2021-08-25T19:43:30.952515Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating a dictionary to store initial results\n",
    "index_label =[f'{train.name}']\n",
    "labels = ['Test Stat','P-Value','Number of Lags Used','Number of Obs. Used',\n",
    "        'Critical Thresholds', 'AIC Value']\n",
    "results_dict  = dict(zip(labels,zipdf_results))\n",
    "\n",
    "## Saving results to a dictionary and adding T/F for whether exceeds standard\n",
    "## p-value of .05 and if we fail to reject the null hypothesis or not.\n",
    "results_dict['p < .05'] = results_dict['P-Value']<.05\n",
    "results_dict['Stationary'] = results_dict['p < .05']\n",
    "\n",
    "## Creating DataFrame from dictionary\n",
    "if isinstance(index_label,str):\n",
    "    index_label = [index_label]\n",
    "results_dict = pd.DataFrame(results_dict,index=index_label)\n",
    "results_dict = results_dict[['Test Stat','P-Value','Number of Lags Used',\n",
    "                             'Number of Obs. Used','P-Value','p < .05',\n",
    "                             'Stationary']]\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:31.198512Z",
     "start_time": "2021-08-25T19:43:31.076514Z"
    }
   },
   "outputs": [],
   "source": [
    "## Functionizing ADF test process\n",
    "\n",
    "def adf_test(ts, p = .05):\n",
    "    zipdf_results = tsa.stattools.adfuller(ts)\n",
    "    \n",
    "    index_label = [f'Results: {ts.name}']\n",
    "    labels = ['Test Stat','P-Value','Number of Lags Used','Number of Obs. Used',\n",
    "            'Critical Thresholds', 'AIC Value']\n",
    "    results_dict  = dict(zip(labels,zipdf_results))\n",
    "\n",
    "    ## Saving results to a dictionary and adding T/F for whether exceeds standard\n",
    "    ## p-value of .05 and if we fail to reject the null hypothesis or not.\n",
    "    results_dict[f'p < {p}'] = results_dict['P-Value']< p\n",
    "    results_dict['Stationary'] = results_dict[f'p < {p}']\n",
    "\n",
    "    ## Creating DataFrame from dictionary\n",
    "    if isinstance(index_label,str):\n",
    "        index_label = [index_label]\n",
    "    results_dict = pd.DataFrame(results_dict,index=index_label)\n",
    "    results_dict = results_dict[['Test Stat','P-Value','Number of Lags Used',\n",
    "                                 'Number of Obs. Used','P-Value',f'p < {p}',\n",
    "                                 'Stationary']]\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:31.309513Z",
     "start_time": "2021-08-25T19:43:31.200515Z"
    }
   },
   "outputs": [],
   "source": [
    "## Testing functionality\n",
    "adf_test(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Trends, Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:31.418514Z",
     "start_time": "2021-08-25T19:43:31.311518Z"
    }
   },
   "outputs": [],
   "source": [
    "## Setting variable for reuse in \n",
    "test_zip = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:31.806514Z",
     "start_time": "2021-08-25T19:43:31.420514Z"
    }
   },
   "outputs": [],
   "source": [
    "## Testing differenced data\n",
    "tz_diff = train.diff().dropna()\n",
    "print(\"|\",\"---\",f\"Zipcode {train.name}\",\"---\",\"|\",\"\\n\")\n",
    "print(tz_diff)\n",
    "print('\\n\\n',\"|\",\"----\"*5,f\"ADF Results for Zipcode {train.name}\",\"-----\"*6,\"|\")\n",
    "display(adf_test(tz_diff))\n",
    "\n",
    "print('\\n\\n','|',\"----\"*7,f\"Visualizing Difference Shift\",\"---\"*7,\"|\")\n",
    "fig, ax = plt.subplots()\n",
    "ax = tz_diff.plot(label=f'{train.name}')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Price ($)')\n",
    "ax.set_title(f'Difference Shift for Zipcode {train.name}')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:31.915549Z",
     "start_time": "2021-08-25T19:43:31.808514Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Functionizing plotting/eval code\n",
    "def remove_trends(timeseries, method, window = 4):\n",
    "    if method == 'diff':\n",
    "        results = timeseries.diff().dropna()\n",
    "    elif method == 'log':\n",
    "        results = np.log(timeseries)\n",
    "    elif method == 'rolling' or method == 'rolling mean':\n",
    "        results = timeseries - timeseries.rolling(window = window).mean()\n",
    "        results.dropna(inplace=True)\n",
    "    elif method == 'ewm' or method == 'EWM':\n",
    "        results = tz_ewm = test_zip-test_zip.ewm(4).mean()\n",
    "        results.dropna(inplace=True)\n",
    "    \n",
    "    print(\"|\",\"---\"*7,f\"{method.title()} Effect on Zipcode {timeseries.name}\",\n",
    "      \"-----\"*6,\"|\",'\\n\\n')\n",
    "    print(\"|\",\"---\",f\"Zipcode {timeseries.name}\",\"---\",\"|\",\"\\n\")\n",
    "    print(results)\n",
    "    print('\\n\\n',\"|\",\"----\"*5,f\"ADF Results for Zipcode {timeseries.name}\",\n",
    "          \"-----\"*6,\"|\")\n",
    "    display(adf_test(results))\n",
    "\n",
    "    print('\\n\\n','|',\"---\"*8,f\"Visualizing {method.title()} Effect\",\"----\"*8,\n",
    "          \"|\")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = results.plot(label=f'{timeseries.name}')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Years')\n",
    "    ax.set_ylabel('Price ($)')\n",
    "    \n",
    "    if method != 'ewm' and method != 'EWM':\n",
    "        ax.set_title(f'{method.title()} Effect on Zipcode {timeseries.name}')\n",
    "    else:\n",
    "        ax.set_title(f'{method.capitalize()} Effect on Zipcode \\\n",
    "                                                        {timeseries.name}')\n",
    "    plt.show();\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:32.304514Z",
     "start_time": "2021-08-25T19:43:31.917514Z"
    }
   },
   "outputs": [],
   "source": [
    "diff_results = remove_trends(train, \"diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:32.775551Z",
     "start_time": "2021-08-25T19:43:32.306526Z"
    }
   },
   "outputs": [],
   "source": [
    "log_results = remove_trends(train, \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:33.179518Z",
     "start_time": "2021-08-25T19:43:32.777517Z"
    }
   },
   "outputs": [],
   "source": [
    "rolling_results = remove_trends(train, \"rolling mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:33.584553Z",
     "start_time": "2021-08-25T19:43:33.181517Z"
    }
   },
   "outputs": [],
   "source": [
    "ewm_results = remove_trends(train, \"EWM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:33.696553Z",
     "start_time": "2021-08-25T19:43:33.586520Z"
    }
   },
   "outputs": [],
   "source": [
    "# methods = ['diff', 'log', 'rolling', 'EWM']\n",
    "\n",
    "# method_results = {}\n",
    "\n",
    "# for method in methods:\n",
    "#     method_results[method] = (remove_trends(train, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:33.789521Z",
     "start_time": "2021-08-25T19:43:33.698541Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(method_results.keys(),\"\\n\\n\")\n",
    "# print(\"'diff' results:\\n\\n\",method_results['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:34.430629Z",
     "start_time": "2021-08-25T19:43:33.791519Z"
    }
   },
   "outputs": [],
   "source": [
    "## Seasonal Decomposition\n",
    "decomp = seasonal_decompose(test_zip)\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:34.772628Z",
     "start_time": "2021-08-25T19:43:34.432630Z"
    }
   },
   "outputs": [],
   "source": [
    "decomp.seasonal.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:34.894661Z",
     "start_time": "2021-08-25T19:43:34.774629Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save seasonal decomposition results to a dictionary.\n",
    "\n",
    "decomp_dict = {'seasonal': decomp.seasonal,\n",
    "              \"trend\": decomp.trend,\n",
    "              'residuals': decomp.resid}\n",
    "\n",
    "decomp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:35.052629Z",
     "start_time": "2021-08-25T19:43:34.896629Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a list of adfuller results to append\n",
    "results = []\n",
    "## Save results of orig ts\n",
    "results.append(adf_test(train))\n",
    "\n",
    "## Loop through decomp dict, \n",
    "for trend, ts_ in decomp_dict.items():\n",
    "    # Fill any missing values, get adfuller result\n",
    "    ts_ = ts_.fillna(0)\n",
    "    res = adf_test(ts_)\n",
    "    results.append(res)\n",
    "\n",
    "    \n",
    "    ## Append res to decomp_stationary\n",
    "\n",
    "## make into a df\n",
    "seasonality_df = pd.concat(results)\n",
    "seasonality_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACF/PACF Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:35.335630Z",
     "start_time": "2021-08-25T19:43:35.054628Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(15, 4))\n",
    "tsa.graphics.plot_acf(train,lags=52, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:35.604246Z",
     "start_time": "2021-08-25T19:43:35.338631Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(15.25, 4))\n",
    "tsa.graphics.plot_pacf(train,lags=52, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:35.700136Z",
     "start_time": "2021-08-25T19:43:35.607017Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_acf_pacf(ts,figsize=(9,6),lags=52,suptitle=None,sup_x = .53, sup_y =1 ):\n",
    "    \"\"\"Plot pacf and acf using statsmodels\n",
    "    \n",
    "    Adapted from: https://github.com/flatiron-school/Online-DS-FT-022221-\\\n",
    "    Cohort-Notes/blob/master/Phase_4/topic_38_time_series_models/topic_38-\\\n",
    "    time_series_models_v3_SG.ipynb\"\"\"\n",
    "    \n",
    "    fig,axes=plt.subplots(nrows=2,figsize=figsize)\n",
    "    \n",
    "    tsa.graphics.plot_acf(ts,ax=axes[0],lags=lags);\n",
    "    tsa.graphics.plot_pacf(ts,ax=axes[1],lags=lags);\n",
    "    \n",
    "    ## Add grid\n",
    "    [ax.grid(axis='both',which='both') for ax in axes]\n",
    "    \n",
    "    axes[0].set_ylabel('Corr. Strength')\n",
    "    axes[1].set_ylabel('Corr. Strength')\n",
    "    \n",
    "    if suptitle is not None:\n",
    "        fig.suptitle(suptitle,x = sup_x, y=sup_y,fontweight='bold',fontsize=15)\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    return fig,axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:36.089632Z",
     "start_time": "2021-08-25T19:43:35.702018Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_acf_pacf(train, suptitle='ACF/PACF for Training Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Best values for `d` and `D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:36.198616Z",
     "start_time": "2021-08-25T19:43:36.091633Z"
    }
   },
   "outputs": [],
   "source": [
    "## Using pmdarima's functions to pre-determine the best values for \n",
    "## differencing prior to running auto_arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:36.292322Z",
     "start_time": "2021-08-25T19:43:36.200588Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Determine best value for d\n",
    "# n_d = ndiffs(train)\n",
    "# n_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:36.384334Z",
     "start_time": "2021-08-25T19:43:36.294293Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Determine best value for D\n",
    "# n_D = nsdiffs(train, m=12)\n",
    "# n_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:36.492326Z",
     "start_time": "2021-08-25T19:43:36.386293Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## Inspecting the training data\n",
    "# train.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:43:36.599295Z",
     "start_time": "2021-08-25T19:43:36.494297Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Using auto_arima to determine best parameters for modeling\n",
    "# auto_model = pmd.auto_arima(train,start_p=0,start_q=0,d=n_d,\n",
    "#                             max_p=3,max_q=3,\n",
    "#                             max_P=3,max_Q=3, D=n_D,\n",
    "#                             start_P=0,start_Q=0,\n",
    "#                             m=12,\n",
    "#                             verbose=2)\n",
    "\n",
    "# display(auto_model.summary())\n",
    "# auto_model.plot_diagnostics(figsize= (12,9));\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:21.276846Z",
     "start_time": "2021-08-25T19:45:19.638842Z"
    }
   },
   "outputs": [],
   "source": [
    "auto_arima_model = tsm.auto_arima_model(train)\n",
    "tsm.model_performance(auto_arima_model, show_vis=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:40.973636Z",
     "start_time": "2021-08-25T19:45:40.872639Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# best_model = tsa.SARIMAX(train,order=auto_model.order,\n",
    "#                          seasonal_order = auto_model.seasonal_order,\n",
    "#                          enforce_invertibility=False).fit()\n",
    "\n",
    "# ## Display Summary + Diagnostics\n",
    "# display(best_model.summary())\n",
    "# best_model.plot_diagnostics(figsize=(12,9));\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:42.081611Z",
     "start_time": "2021-08-25T19:45:40.975612Z"
    }
   },
   "outputs": [],
   "source": [
    "auto_model, best_model = tsm.create_best_model(train, m=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Best Model & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:42.190610Z",
     "start_time": "2021-08-25T19:45:42.084613Z"
    }
   },
   "outputs": [],
   "source": [
    "# def calc_plot_best_model(train,start_p=0,max_p=5,start_q=0,max_q=5,d=1,m=52,\n",
    "#                          start_P=0,start_Q=0, max_P=3, max_Q = 3, verbose = True):\n",
    "    \n",
    "#     auto_model = pmd.auto_arima(train, start_p = start_p, max_p = max_p,\n",
    "#                            start_q = start_q, max_q = max_q, d = d ,m = m,\n",
    "#                            start_P = start_P, start_Q = start_Q,\n",
    "#                                 max_P = max_P, verbose=verbose)\n",
    "    \n",
    "#     display(auto_model.summary())\n",
    "    \n",
    "#     best_model = tsa.SARIMAX(train,order=auto_model.order,\n",
    "#                              seasonal_order = auto_model.seasonal_order,\n",
    "#                              enforce_invertibility=False).fit()\n",
    "    \n",
    "#     ## Display Summary + Diagnostics\n",
    "#     display(best_model.summary())\n",
    "#     best_model.plot_diagnostics();\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     return auto_model, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:42.299647Z",
     "start_time": "2021-08-25T19:45:42.192612Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Using get_forecast to generate forecasted data\n",
    "# forecast = best_model.get_forecast(steps=len(test))\n",
    "\n",
    "# ## Saving confidence intervals and predicted mean for future\n",
    "# forecast_df = forecast.conf_int()\n",
    "# forecast_df.columns = ['Lower CI','Upper CI']\n",
    "# forecast_df['Forecast'] = forecast.predicted_mean\n",
    "# forecast_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:42.423640Z",
     "start_time": "2021-08-25T19:45:42.301637Z"
    }
   },
   "outputs": [],
   "source": [
    "forecast_df = tsm.forecast_and_ci(best_model, test_data = test)\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:42.517641Z",
     "start_time": "2021-08-25T19:45:42.425613Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Plotting training, test data and forecasted results\n",
    "# fig,ax = plt.subplots(figsize=(13,6))\n",
    "\n",
    "# last_n_lags=12*5         \n",
    "\n",
    "# train.iloc[-last_n_lags:].plot(label='Training Data')\n",
    "# test.plot(label='Test Data')\n",
    "\n",
    "# ## Plotting forecasted data and confidence intervals\n",
    "# forecast_df['Forecast'].plot(ax=ax,label='Forecast')\n",
    "# ax.fill_between(forecast_df.index,forecast_df['Lower CI'],\n",
    "#                 forecast_df['Upper CI'],color='b',alpha=0.4)\n",
    "\n",
    "# ax.set(xlabel='Time')\n",
    "# ax.set(ylabel='Sell Price ($)')\n",
    "# ax.set_title('Data and Forecasted Data')\n",
    "# ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:42.704613Z",
     "start_time": "2021-08-25T19:45:42.520629Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = tsm.plot_forecast_ttf(train=train, test=test,\n",
    "                                forecast_df = forecast_df, n_yrs_past=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:42.970652Z",
     "start_time": "2021-08-25T19:45:42.708615Z"
    }
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Save `conf_int`, `predicted_mean` - 4cDF\n",
    ">\n",
    ">\n",
    "> Plot Tr, Te, 4cDF\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:43.065641Z",
     "start_time": "2021-08-25T19:45:42.972615Z"
    }
   },
   "outputs": [],
   "source": [
    "# best_model = tsa.SARIMAX(zipcode_val,order=auto_model.order,\n",
    "#                          seasonal_order = auto_model.seasonal_order,\n",
    "#                          enforce_invertibility=False).fit()\n",
    "\n",
    "# display(best_model.summary())\n",
    "# best_model.plot_diagnostics(figsize=(12,9));\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:44.125615Z",
     "start_time": "2021-08-25T19:45:43.067617Z"
    }
   },
   "outputs": [],
   "source": [
    "auto_model_best, best_model_overall = tsm.create_best_model(zipcode_val, m=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:44.250617Z",
     "start_time": "2021-08-25T19:45:44.127617Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Using get_forecast to generate forecasted data\n",
    "# forecast = best_model.get_forecast(steps=24)\n",
    "\n",
    "# ## Saving confidence intervals and predicted mean for future\n",
    "# forecast_df = forecast.conf_int()\n",
    "# forecast_df.columns = ['Lower CI','Upper CI']\n",
    "# forecast_df['Forecast'] = forecast.predicted_mean\n",
    "# forecast_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:44.358618Z",
     "start_time": "2021-08-25T19:45:44.252617Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Plotting training, test data and forecasted results\n",
    "# fig,ax = plt.subplots(figsize=(13,6))\n",
    "\n",
    "# zipcode_val.plot(label='Training Data')\n",
    "\n",
    "# ## Plotting forecasted data and confidence intervals\n",
    "# forecast_df['Forecast'].plot(ax=ax,label='Forecast')\n",
    "# ax.fill_between(forecast_df.index,forecast_df['Lower CI'],\n",
    "#                 forecast_df['Upper CI'],color='b',alpha=0.4)\n",
    "\n",
    "# ax.set(xlabel='Time')\n",
    "# ax.set(ylabel='Sale Price ($)')\n",
    "# ax.set_title('Data and Forecasted Data')\n",
    "# ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:44.483652Z",
     "start_time": "2021-08-25T19:45:44.360620Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast_overall = tsm.forecast_and_ci(best_model_overall, n_yrs_future = 2)\n",
    "forecast_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:44.810646Z",
     "start_time": "2021-08-25T19:45:44.485617Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = tsm.plot_forecast_final(zipcode_val, forecast_overall)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:44.904619Z",
     "start_time": "2021-08-25T19:45:44.812620Z"
    }
   },
   "outputs": [],
   "source": [
    "investment_cost = forecast_df.iloc[0,2]\n",
    "investment_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.011620Z",
     "start_time": "2021-08-25T19:45:44.906621Z"
    }
   },
   "outputs": [],
   "source": [
    "roi_df = (forecast_df - investment_cost)/investment_cost*100\n",
    "roi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.120658Z",
     "start_time": "2021-08-25T19:45:45.014621Z"
    }
   },
   "outputs": [],
   "source": [
    "roi_final = roi_df.iloc[-1]\n",
    "roi_final.name = zipcode_val.name.astype('str')\n",
    "roi_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.216620Z",
     "start_time": "2021-08-25T19:45:45.122622Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(roi_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Based on my model, the ROI for the zipcode 15206 would be an average of 65.48%. However, the results may fall anywhere between 19.05% - 111.91%.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionalizing Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T20:23:03.174293Z",
     "start_time": "2021-08-25T20:23:00.989291Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Testing full workflow function\n",
    "\n",
    "forecast, roi, summary_train, diag_train, summary_full,\\\n",
    "diag_full, training_frcst, final_frcst = tsm.ts_modeling_workflow\\\n",
    "    (dataframe = zipcodes_df, zipcode = 15206, m=12, show_vis = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T20:18:37.740771Z",
     "start_time": "2021-08-25T20:18:36.408923Z"
    }
   },
   "outputs": [],
   "source": [
    "zc_dict = tsm.make_dict(zipcodes_df, 15206)\n",
    "zc_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T20:18:37.849227Z",
     "start_time": "2021-08-25T20:18:37.742745Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting \"forecasted prices\" key\n",
    "zc_dict['forecasted_prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T20:18:38.021227Z",
     "start_time": "2021-08-25T20:18:37.930202Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Inspecting \"forecasted prices\" key\n",
    "zc_dict['ROI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T20:18:49.867201Z",
     "start_time": "2021-08-25T20:18:49.768230Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting \"forecasted prices\" key\n",
    "zc_dict['model_metrics'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T20:23:45.471082Z",
     "start_time": "2021-08-25T20:23:45.369049Z"
    }
   },
   "outputs": [],
   "source": [
    "zc_dict['model_metrics']['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T20:24:19.164107Z",
     "start_time": "2021-08-25T20:24:18.776136Z"
    }
   },
   "outputs": [],
   "source": [
    "zc_dict['model_metrics']['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T20:24:54.139494Z",
     "start_time": "2021-08-25T20:24:54.026465Z"
    }
   },
   "outputs": [],
   "source": [
    "zc_dict['model_metrics']['full'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.350620Z",
     "start_time": "2021-08-25T19:45:40.976Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting training model performance\n",
    "train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.351620Z",
     "start_time": "2021-08-25T19:45:40.980Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reviewing final model performance\n",
    "final_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.352619Z",
     "start_time": "2021-08-25T19:45:40.985Z"
    }
   },
   "outputs": [],
   "source": [
    "training_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.353623Z",
     "start_time": "2021-08-25T19:45:40.989Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Results (Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> [See this link](https://www.youtube.com/watch?v=GHFEYSX-cIk&list=PLFknVelSJiSxSwXifV_ysDg50fzbuTzVt&index=58)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Remaining Zip Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Now I will process the remaining zip codes of the 10-year zipcode dataframe.\n",
    ">\n",
    ">\n",
    "> **To make the process easier, I converted the modeling process into a single function, accessible in my personal module in this repository.**\n",
    ">\n",
    ">\n",
    "> I will loop through the remaining zipcodes and run them through the workflow. As part of the workflow, I will review each model's performance to ensure it is appropriate for forecasting.\n",
    ">\n",
    ">\n",
    ">I will save the results to the overall dictionary for my final review and interpretation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.354622Z",
     "start_time": "2021-08-25T19:45:40.998Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Creating dictionary to store all zipcodes and results\n",
    "# overall_results = {}\n",
    "\n",
    "# for zipcode in zipcodes_df.columns:\n",
    "    \n",
    "#     zip_tsa_results = {}\n",
    "#     metrics = {}\n",
    "#     forecast_vis = {}\n",
    "    \n",
    "#     forecast_full, roi_final, summary_train, diag_train, summary_full,\\\n",
    "#     diag_full, training_frcst, final_frcst = tsm\\\n",
    "#                                 .ts_modeling_workflow(dataframe = zipcodes_df,\n",
    "#                                                       zipcode = 15206, m=12,\n",
    "#                                                       show_vis = False)\n",
    "    \n",
    "#     metrics['train'] = [summary_train, diag_train]\n",
    "#     metrics['full'] = [summary_full, diag_full] \n",
    "#     forecast_vis['train'] = training_frcst\n",
    "#     forecast_vis['full'] = final_frcst\n",
    "    \n",
    "#     zip_tsa_results['forecasted prices'] = forecast\n",
    "#     zip_tsa_results['ROI'] = roi_final\n",
    "#     zip_tsa_results['model_metrics'] = metrics\n",
    "#     zip_tsa_results['model_visuals'] = forecast_vis\n",
    "    \n",
    "#     overall_results[zipcode] = zip_tsa_results\n",
    "    \n",
    "#     print(f'Completed {zipcode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.355622Z",
     "start_time": "2021-08-25T19:45:41.004Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## Creating dictionary to store all zipcodes and results\n",
    "# overall_results = {}\n",
    "\n",
    "# for zipcode in zipcodes_df.columns:\n",
    "    \n",
    "#     overall_results['zipcode'] = tsm.make_dict(dataframe = zipcodes_df,\n",
    "#                                            zipcode = zipcode)\n",
    "#     print(f'Completed {zipcode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.356621Z",
     "start_time": "2021-08-25T19:45:41.008Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.357621Z",
     "start_time": "2021-08-25T19:45:41.013Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_results[15206].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.358635Z",
     "start_time": "2021-08-25T19:45:41.017Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overall_results[15206]['forecasted prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.360622Z",
     "start_time": "2021-08-25T19:45:41.022Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_results[15206]['ROI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.361622Z",
     "start_time": "2021-08-25T19:45:41.026Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_results[15206]['model_metrics'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.361622Z",
     "start_time": "2021-08-25T19:45:41.031Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_results[15206]['model_metrics']['train']['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.362629Z",
     "start_time": "2021-08-25T19:45:41.039Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_results[15206]['model_metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❌ **RAISE ERROR** ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging code for auto_arima settings (LU decomp error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.363633Z",
     "start_time": "2021-08-25T19:45:41.053Z"
    }
   },
   "outputs": [],
   "source": [
    "zipcodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.364621Z",
     "start_time": "2021-08-25T19:45:41.058Z"
    }
   },
   "outputs": [],
   "source": [
    "## Determine best value for d\n",
    "n_d = ndiffs(zipcodes_df[15210])\n",
    "n_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.365630Z",
     "start_time": "2021-08-25T19:45:41.063Z"
    }
   },
   "outputs": [],
   "source": [
    "## Determine best value for D\n",
    "n_D = nsdiffs(zipcodes_df[15210], m=12)\n",
    "n_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.366619Z",
     "start_time": "2021-08-25T19:45:41.072Z"
    }
   },
   "outputs": [],
   "source": [
    "zipcodes_df[15210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.367622Z",
     "start_time": "2021-08-25T19:45:41.080Z"
    }
   },
   "outputs": [],
   "source": [
    "auto_model = pmd.auto_arima(zipcodes_df[15210],start_p=0,start_q=0,d=n_d,\n",
    "                            max_p=3,max_q=3,\n",
    "                            max_P=3,max_Q=3, D=n_D,\n",
    "                            start_P=0,start_Q=0,\n",
    "                            m=12,\n",
    "                            verbose=2)\n",
    "\n",
    "display(auto_model.summary())\n",
    "auto_model.plot_diagnostics(figsize= (12,9));\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.368629Z",
     "start_time": "2021-08-25T19:45:41.089Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = tsa.SARIMAX(zipcodes_df[15210],order=auto_model.order,\n",
    "                         seasonal_order = auto_model.seasonal_order,\n",
    "                         enforce_invertibility=False).fit()\n",
    "\n",
    "## Display Summary + Diagnostics\n",
    "display(best_model.summary())\n",
    "best_model.plot_diagnostics(figsize=(12,9));\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.369622Z",
     "start_time": "2021-08-25T19:45:41.098Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zip_15210 = tsm.make_dict(zipcodes_df, 15210)\n",
    "zip_15210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.370621Z",
     "start_time": "2021-08-25T19:45:41.105Z"
    }
   },
   "outputs": [],
   "source": [
    "zip_15210_auto, zip_15210_best = tsm.create_best_model(zipcodes_df[15210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.371620Z",
     "start_time": "2021-08-25T19:45:41.114Z"
    }
   },
   "outputs": [],
   "source": [
    "raise ValueError('Old notebook code below - DO NOT RUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.372621Z",
     "start_time": "2021-08-25T19:45:41.122Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsm.model_performance(zip_15210_best, show_vis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manually code, then  functionize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.374620Z",
     "start_time": "2021-08-25T19:45:41.131Z"
    }
   },
   "outputs": [],
   "source": [
    "def forecast_and_plot(train, test, final_ts = None, model, last_n_lags=52,\n",
    "                      x_label, y_label, figsize=(10,4)):\n",
    "\n",
    "    ## Get forecast\n",
    "    forecast = model.get_forecast(steps=len(test))\n",
    "\n",
    "    ## Save forecasted mean, upper/lower CI as DF\n",
    "    forecast_df = forecast.conf_int()\n",
    "    forecast_df.columns = ['Lower CI','Upper CI']\n",
    "    forecast_df['Forecast'] = forecast.predicted_mean\n",
    "\n",
    "    # Plotting timeseries data\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    last_n_lags=last_n_lags\n",
    "    \n",
    "    if final_ts is None:\n",
    "        train.iloc[-last_n_lags:].plot(label='Training Data')\n",
    "        test.plot(label='Test Data')\n",
    "    else:\n",
    "        ts.iloc[-last_n_lags:].plot(label='Training Data')\n",
    "        ax.axvline(ts.index[-1],ls=':')\n",
    "\n",
    "    ## Plotting forecast and CI\n",
    "    forecast_df['Forecast'].plot(ax=ax,label='Forecast')\n",
    "    ax.fill_between(forecast_df.index,\n",
    "                    forecast_df['Lower CI'], \n",
    "                    forecast_df['Upper CI'],color='g',alpha=0.3)\n",
    "\n",
    "    ax.set(xlabel=x_label)\n",
    "    ax.set(ylabel=y_label)\n",
    "    ax.legend()\n",
    "    plt.show();\n",
    "    \n",
    "    return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.375620Z",
     "start_time": "2021-08-25T19:45:41.138Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_df_from_pred(forecast_or_pred,forecast_label='Forecast'):\n",
    "    \"\"\"Takes a PredictionResultsWrapper from statsmodels\n",
    "    extracts the confidence intervals and predicted mean and returns in a df\"\"\"\n",
    "    forecast_df = forecast_or_pred.conf_int()\n",
    "    forecast_df.columns = ['Lower CI','Upper CI']\n",
    "    forecast_df[forecast_label] = forecast_or_pred.predicted_mean\n",
    "    return forecast_df\n",
    "\n",
    "def plot_forecast_from_df(forecast_df,ts_diff=None,orig_label='True Data',\n",
    "                          forecast_label='Forecast',\n",
    "                          last_n_lags=52,figsize=(10,4)):\n",
    "    \"\"\"Takes a forecast_df from get_df_from_pred and optionally \n",
    "    the training/original time series.\n",
    "    \n",
    "    Plots the original ts, the predicted mean and the \n",
    "    confidence invtervals (using fill between)\"\"\"\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    if ts_diff is not None:\n",
    "        ts_diff.iloc[-last_n_lags:].plot(label='True Data')\n",
    "        \n",
    "   \n",
    "    forecast_df['Forecast'].plot(ax=ax,label=forecast_label)\n",
    "    ax.fill_between(forecast_df.index,\n",
    "                    forecast_df['Lower CI'], \n",
    "                    forecast_df['Upper CI'],color='g',alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set(title=f'Forecasted {ts_diff.name}')\n",
    "    return fig,ax\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Full Dataset for Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.376620Z",
     "start_time": "2021-08-25T19:45:41.151Z"
    }
   },
   "outputs": [],
   "source": [
    "## If happy with the model's test perforamance, retrain on entire ts and forecast into future\n",
    "## Fit a final model and evaluate\n",
    "final_model = tsa.SARIMAX(ts,order=auto_model.order,\n",
    "                seasonal_order = auto_model.seasonal_order,\n",
    "                enforce_invertibility=False).fit()\n",
    "\n",
    "\n",
    "## Display Summary + Diagnostics\n",
    "display(final_model.summary())\n",
    "final_model.plot_diagnostics();\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.377621Z",
     "start_time": "2021-08-25T19:45:41.157Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get forecast \n",
    "forecast = final_model.get_forecast(steps=len(test))\n",
    "\n",
    "## save forecasted mean and upper/lower ci as df\n",
    "forecast_df = forecast.conf_int()\n",
    "forecast_df.columns = ['Lower CI','Upper CI']\n",
    "forecast_df['Forecast'] = forecast.predicted_mean\n",
    "\n",
    "## Plot\n",
    "last_n_lags=52\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "                      \n",
    "# Plotting Training and test data\n",
    "ts.iloc[-last_n_lags:].plot(label='Training Data')\n",
    "ax.axvline(ts.index[-1],ls=':')\n",
    "# test.plot(label='Test Data')\n",
    "\n",
    "## Plotting Forefcast and CI\n",
    "forecast_df['Forecast'].plot(ax=ax,label='Forecast')\n",
    "ax.fill_between(forecast_df.index,\n",
    "                forecast_df['Lower CI'], \n",
    "                forecast_df['Upper CI'],color='g',alpha=0.3)\n",
    "\n",
    "ax.set(ylabel='Crime Count')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 4 Project - Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been provided to you so that you can make use of the following starter code to help with the trickier parts of preprocessing the Zillow dataset. \n",
    "\n",
    "The notebook contains a rough outline the general order you'll likely want to take in this project. You'll notice that most of the areas are left blank. This is so that it's more obvious exactly when you should make use of the starter code provided for preprocessing. \n",
    "\n",
    "**_NOTE:_** The number of empty cells are not meant to infer how much or how little code should be involved in any given step--we've just provided a few for your convenience. Add, delete, and change things around in this notebook as needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Notes Before Starting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will be one of the more challenging projects you complete in this program. This is because working with Time Series data is a bit different than working with regular datasets. In order to make this a bit less frustrating and help you understand what you need to do (and when you need to do it), we'll quickly review the dataset formats that you'll encounter in this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide Format vs Long Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look at the format of the data in `zillow_data.csv`, you'll notice that the actual Time Series values are stored as separate columns. Here's a sample: \n",
    "\n",
    "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-mod-4-project-seattle-ds-102819/master/images/df_head.png'>\n",
    "\n",
    "You'll notice that the first seven columns look like any other dataset you're used to working with. However, column 8 refers to the median housing sales values for April 1996, column 9 for May 1996, and so on. This This is called **_Wide Format_**, and it makes the dataframe intuitive and easy to read. However, there are problems with this format when it comes to actually learning from the data, because the data only makes sense if you know the name of the column that the data can be found it. Since column names are metadata, our algorithms will miss out on what dates each value is for. This means that before we pass this data to our ARIMA model, we'll need to reshape our dataset to **_Long Format_**. Reshaped into long format, the dataframe above would now look like:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-mod-4-project-seattle-ds-102819/master/images/melted1.png'>\n",
    "\n",
    "There are now many more rows in this dataset--one for each unique time and zipcode combination in the data! Once our dataset is in this format, we'll be able to train an ARIMA model on it. The method used to convert from Wide to Long is `pd.melt()`, and it is common to refer to our dataset as 'melted' after the transition to denote that it is in long format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions Provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melting a dataset can be tricky if you've never done it before, so you'll see that we have provided a sample function, `melt_data()`, to help you with this step below. Also provided is:\n",
    "\n",
    "* `get_datetimes()`, a function to deal with converting the column values for datetimes as a pandas series of datetime objects\n",
    "* Some good parameters for matplotlib to help make your visualizations more readable. \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.378621Z",
     "start_time": "2021-08-25T19:45:41.176Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # import warnings\n",
    "# # warnings.filterwarnings('ignore')\n",
    "\n",
    "# ## Data Handling\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# ## Visualizations\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# import statsmodels\n",
    "# import statsmodels.tsa.api as tsa\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# import pmdarima as pmd\n",
    "\n",
    "# ## Settings\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize']=(12,6)\n",
    "# plt.style.use('seaborn-talk')\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "# pd.set_option('max_rows', 100)\n",
    "\n",
    "# from bmc_functions import eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.381620Z",
     "start_time": "2021-08-25T19:45:41.182Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.382621Z",
     "start_time": "2021-08-25T19:45:41.188Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## ImportingReading in-Dta\n",
    "# source = '../data/zillow_data.csv'\n",
    "# data = pd.read_csv(source)\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.383621Z",
     "start_time": "2021-08-25T19:45:41.196Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "> The dataset is much larger than I need for my purposes, so I will determine a smaller regional subset for analysis.\n",
    ">\n",
    ">\n",
    "> As I am from Pittsburgh, PA, I will select that region for my models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.384620Z",
     "start_time": "2021-08-25T19:45:41.208Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Selecting Pittsburgh Metro Area\n",
    "\n",
    "# pitt_df = data[data['City'] == 'Pittsburgh']\n",
    "# pitt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.385620Z",
     "start_time": "2021-08-25T19:45:41.215Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## Examining Statistics for the Pittsburgh Metro area\n",
    "# eda.report_df(pitt_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.386620Z",
     "start_time": "2021-08-25T19:45:41.222Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Inspecting overall data for CA - transposed and dropping RegionID, SizeRank\n",
    "\n",
    "# pitt_zips = pitt_df.pivot_table(index= 'RegionName').T[:-2]\n",
    "# pitt_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.387620Z",
     "start_time": "2021-08-25T19:45:41.230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def get_datetimes(df):\n",
    "#     \"\"\"\n",
    "#     Takes a dataframe:\n",
    "#     returns only those column names that can be converted into datetime objects \n",
    "#     as datetime objects.\n",
    "#     NOTE number of returned columns may not match total number of columns in passed dataframe\n",
    "#     \"\"\"\n",
    "    \n",
    "#     return pd.to_datetime(df.columns.values[7:], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.388649Z",
     "start_time": "2021-08-25T19:45:41.235Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pitt_df.columns.values[7:] = get_datetimes(pitt_df)\n",
    "# pitt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Melting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.389619Z",
     "start_time": "2021-08-25T19:45:41.244Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def melt_data(df):\n",
    "#     \"\"\"\n",
    "#     Takes the zillow_data dataset in wide form or a subset of the zillow_dataset.  \n",
    "#     Returns a long-form datetime dataframe with the datetime column names\n",
    "#     as the index and the values as the 'values' column.\n",
    "    \n",
    "#     If more than one row is passes in the wide-form dataset, the values column\n",
    "#     will be the mean of the values from the datetime columns in all of the rows.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     melted = pd.melt(df, id_vars=['RegionName', 'RegionID', 'SizeRank',\n",
    "#                                   'City', 'State', 'Metro', 'CountyName'],\n",
    "#                      var_name='time')\n",
    "#     melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "#     melted = melted.dropna(subset=['value'])\n",
    "#     return melted#.groupby('time').aggregate({'value':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.390628Z",
     "start_time": "2021-08-25T19:45:41.250Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pitt_melted = melt_data(pitt_df)\n",
    "# pitt_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Old Code - Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.392630Z",
     "start_time": "2021-08-25T19:45:41.260Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Inspecting overall data for Pittsburgh\n",
    "\n",
    "# pitt_df.pivot_table(index= 'RegionName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.394622Z",
     "start_time": "2021-08-25T19:45:41.266Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Inspecting overall data for CA - transposed and dropping RegionID, SizeRank\n",
    "\n",
    "# pitt_zips = pitt_df.pivot_table(index= 'RegionName').T[:-2]\n",
    "# pitt_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Step 3: EDA and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.395623Z",
     "start_time": "2021-08-25T19:45:41.276Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# font = {'family' : 'normal',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : 22}\n",
    "\n",
    "# mpl.rc('font', **font)\n",
    "\n",
    "# # NOTE: if you visualizations are too cluttered to read, try calling 'plt.gcf().autofmt_xdate()'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.397622Z",
     "start_time": "2021-08-25T19:45:41.283Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Generating initial statistical overview\n",
    "# report = eda.report_df(pitt_df)\n",
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.398623Z",
     "start_time": "2021-08-25T19:45:41.290Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Inspecting only zip codes with missing columns\n",
    "# report[report['null_sum'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.400620Z",
     "start_time": "2021-08-25T19:45:41.298Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Selecting zipcode with largest number of entries\n",
    "# most_freq_zip = report['count'].sort_values(ascending=False)[:1]\n",
    "# most_freq_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.401620Z",
     "start_time": "2021-08-25T19:45:41.305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Checking for missing values pre-visualizing\n",
    "# pitt_zips[15243].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.403621Z",
     "start_time": "2021-08-25T19:45:41.310Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test_zip = pitt_zips[15243]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.404623Z",
     "start_time": "2021-08-25T19:45:41.316Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## Initial visualization of one zipcode\n",
    "# test_zip.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIX/REMOVE JMI FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.406621Z",
     "start_time": "2021-08-25T19:45:41.323Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Lab Function\n",
    "# # from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# def adfuller_test_df(ts,index=['AD Fuller Results']):\n",
    "#     \"\"\"Returns the AD Fuller Test Results and p-values for the null hypothesis\n",
    "#     that there the data is non-stationary (that there is a unit root in the data)\"\"\"\n",
    "    \n",
    "#     df_res = tsa.stattools.adfuller(ts)\n",
    "    \n",
    "#     names = ['Test Statistic','p-value','#Lags Used','# of Observations Used']\n",
    "#     res  = dict(zip(names,df_res[:4]))\n",
    "    \n",
    "#     res['p<.05'] = res['p-value']<.05\n",
    "#     res['Stationary?'] = res['p<.05']\n",
    "    \n",
    "#     if isinstance(index,str):\n",
    "#         index = [index]\n",
    "#     res_df = pd.DataFrame(res,index=index)\n",
    "#     res_df = res_df[['Test Statistic','#Lags Used',\n",
    "#                      '# of Observations Used','p-value','p<.05',\n",
    "#                     'Stationary?']]\n",
    "#     return res_df\n",
    "\n",
    "\n",
    "\n",
    "# def stationarity_check(TS,window=8,plot=True,index=['AD Fuller Results']):\n",
    "#     \"\"\"Adapted from https://github.com/learn-co-curriculum/dsc-removing-trends-lab/tree/solution\"\"\"\n",
    "    \n",
    "#     # Calculate rolling statistics\n",
    "#     roll_mean = TS.rolling(window=window, center=False).mean()\n",
    "#     roll_std = TS.rolling(window=window, center=False).std()\n",
    "    \n",
    "#     # Perform the Dickey Fuller Test\n",
    "#     dftest = adfuller_test_df(TS,index=index)\n",
    "    \n",
    "#     if plot:\n",
    "#         # Plot rolling statistics:\n",
    "#         fig = plt.figure(figsize=(12,6))\n",
    "#         plt.plot(TS, color='blue',label=f'Original (freq={TS.index.freq})')\n",
    "#         plt.plot(roll_mean, color='red', label=f'Rolling Mean (window={window})')\n",
    "#         plt.plot(roll_std, color='black', label = f'Rolling Std (window={window})')\n",
    "#         plt.legend(loc='best')\n",
    "#         plt.title('Rolling Mean & Standard Deviation')\n",
    "#         display(dftest)\n",
    "#         plt.show(block=False)\n",
    "        \n",
    "#     return dftest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.407622Z",
     "start_time": "2021-08-25T19:45:41.330Z"
    }
   },
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.stattools import adfuller\n",
    "# results = stationarity_check(test_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.408621Z",
     "start_time": "2021-08-25T19:45:41.337Z"
    }
   },
   "outputs": [],
   "source": [
    "# tz_diff = test_zip.diff().dropna()\n",
    "# tz_diff.plot()\n",
    "# adfuller_test_df(tz_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.409623Z",
     "start_time": "2021-08-25T19:45:41.344Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Log Transform, plot and get adfuller test\n",
    "# tz_log = np.log(test_zip)\n",
    "# tz_log.plot()\n",
    "# adfuller_test_df(tz_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.410622Z",
     "start_time": "2021-08-25T19:45:41.351Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Subtract Rolling mean\n",
    "# tz_rm = test_zip - test_zip.rolling(window=4).mean()\n",
    "# tz_rm.dropna(inplace=True)\n",
    "# tz_rm.plot()\n",
    "# adfuller_test_df(tz_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.411626Z",
     "start_time": "2021-08-25T19:45:41.356Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tz_ewm = test_zip-test_zip.ewm(4).mean()\n",
    "# tz_ewm.dropna(inplace=True)\n",
    "# tz_ewm.plot()\n",
    "# adfuller_test_df(tz_ewm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.412621Z",
     "start_time": "2021-08-25T19:45:41.362Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decomp = seasonal_decompose(test_zip)\n",
    "# decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.414627Z",
     "start_time": "2021-08-25T19:45:41.369Z"
    }
   },
   "outputs": [],
   "source": [
    "# decomp.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.414627Z",
     "start_time": "2021-08-25T19:45:41.377Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Save seasonal/trend/resid in a dictionary.\n",
    "\n",
    "# decomp_dict = {'seasonal': decomp.seasonal,\n",
    "#               \"trend\": decomp.trend,\n",
    "#               'residuals': decomp.resid}\n",
    "\n",
    "# decomp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.415622Z",
     "start_time": "2021-08-25T19:45:41.383Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Make a list of adfuller results to append\n",
    "# results = []\n",
    "# ## Save results of orig ts\n",
    "# results.append(adfuller_test_df(test_zip,index=['Original']))\n",
    "\n",
    "# ## Loop through decomp dict, \n",
    "# for trend, ts_ in decomp_dict.items():\n",
    "#     # Fill any missing values, get adfuller result\n",
    "#     ts_ = ts_.fillna(0)\n",
    "#     res = adfuller_test_df(ts_,index=trend)\n",
    "#     results.append(res)\n",
    "\n",
    "    \n",
    "#     ## Append res to decomp_stationary\n",
    "\n",
    "# ## make into a df\n",
    "# res_df = pd.concat(results)\n",
    "# res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.417621Z",
     "start_time": "2021-08-25T19:45:41.389Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Pldot decomp again for convenient comparison\n",
    "# decomp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: ARIMA Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.418621Z",
     "start_time": "2021-08-25T19:45:41.395Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_zip.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.420622Z",
     "start_time": "2021-08-25T19:45:41.400Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Use auto_arima \n",
    "# auto_model = pmd.auto_arima(test_zip.loc['2008':],start_p=0,start_q=0,d=1,\n",
    "#                             max_p=3,max_q=3,\n",
    "#                             max_P=3,max_Q=3,\n",
    "#                             start_P=0,start_Q=0,\n",
    "#                             m=12,\n",
    "#                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.421622Z",
     "start_time": "2021-08-25T19:45:41.407Z"
    }
   },
   "outputs": [],
   "source": [
    "# display(auto_model.summary())\n",
    "# auto_model.plot_diagnostics();\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.422635Z",
     "start_time": "2021-08-25T19:45:41.413Z"
    }
   },
   "outputs": [],
   "source": [
    "# tz_diff = test_zip.diff().dropna()\n",
    "# tz_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.423621Z",
     "start_time": "2021-08-25T19:45:41.418Z"
    }
   },
   "outputs": [],
   "source": [
    "# adfuller_test_df(tz_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.425621Z",
     "start_time": "2021-08-25T19:45:41.425Z"
    }
   },
   "outputs": [],
   "source": [
    "# am_diff = pmd.auto_arima(test_zip,start_p=0,start_q=0, d=1,\n",
    "#                             max_p=4,max_q=3,\n",
    "#                             max_P=3,max_Q=2,\n",
    "#                             start_P=0,start_Q=0,\n",
    "#                             m=12,\n",
    "#                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.425621Z",
     "start_time": "2021-08-25T19:45:41.432Z"
    }
   },
   "outputs": [],
   "source": [
    "# display(am_diff.summary())\n",
    "# am_diff.plot_diagnostics();\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.426621Z",
     "start_time": "2021-08-25T19:45:41.439Z"
    }
   },
   "outputs": [],
   "source": [
    "# ### From SARIMA Models Lab\n",
    "# import itertools\n",
    "# from tqdm.notebook import trange\n",
    "# # Define the p, d and q parameters to take any value between 0 and 2\n",
    "# ps = list(range(0,4))\n",
    "# ds = list(range(0,2))\n",
    "# qs = list(range(0,3))\n",
    "\n",
    "# # Generate all different combinations of p, q and q triplets\n",
    "# pdq_list = list(itertools.product(ps,ds, qs))\n",
    "# pdq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T19:45:45.427621Z",
     "start_time": "2021-08-25T19:45:41.447Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Loop through pdq_list, make an ARIMA model\n",
    "# # save p,d,q and aic to a model_aic list\n",
    "# model_aics= [['p','d','q','aic']]\n",
    "\n",
    "# ## Make Results into a df and sort by aic\n",
    "# for i in trange(len(pdq_list)):\n",
    "#     p,d,q = pdq_list[i]\n",
    "#     model = tsa.arima.ARIMA(ts,order=(p,d,q),enforce_invertibility=False).fit()\n",
    "#     model_aics.append([p,d,q,model.aic])\n",
    "#     print(f'For ({p},{d},{q}), aic = {model.aic:.3f}')\n",
    "\n",
    "# results = pd.DataFrame(model_aics[1:],columns=model_aics[0]).sort_values('aic')\n",
    "# results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "331px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
