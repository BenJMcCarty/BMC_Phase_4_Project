{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Guiding question:** What are the top 3 zip codes for short-term investment (based on ROI) and the worst 3 (based on risk) in the city of Pittsburgh, PA?\n",
    ">\n",
    ">\n",
    "> **Evaluation Metric:** ROI/Risk\n",
    ">\n",
    ">\n",
    "> **Dataset:** Zillow data from 1996-2018\n",
    ">\n",
    ">\n",
    "> **Goal:** Determine ROI and risk via time series forecasting \n",
    ">\n",
    ">\n",
    "> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:15.867192Z",
     "start_time": "2021-08-26T22:30:12.748954Z"
    }
   },
   "outputs": [],
   "source": [
    "## Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Time Series Modeling\n",
    "import statsmodels\n",
    "import statsmodels.tsa.api as tsa\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import pmdarima as pmd\n",
    "from pmdarima.arima import ndiffs\n",
    "from pmdarima.arima import nsdiffs\n",
    "\n",
    "## Custom-made Functions\n",
    "from bmc_functions import eda\n",
    "from bmc_functions import time_series_modeling as tsm\n",
    "\n",
    "## Settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-talk')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "pd.set_option('max_rows', 100)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:16.615163Z",
     "start_time": "2021-08-26T22:30:15.869967Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Reading data\n",
    "source = '../data/zillow_data.csv'\n",
    "data = pd.read_csv(source)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:16.739162Z",
     "start_time": "2021-08-26T22:30:16.617134Z"
    }
   },
   "outputs": [],
   "source": [
    "## Initial inspection\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Subset of Zipcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The dataset is much larger than I need for my purposes, so I will select only the zip codes for the Pittsburgh Metro area.\n",
    ">\n",
    ">\n",
    "> To select this data, I will filter the initial dataframe by selecting \"Pittsburgh\" from the \"city\" column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:17.050640Z",
     "start_time": "2021-08-26T22:30:16.742133Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Selecting the city of Pittsburgh \n",
    "pitt_df = data[data['City'] == 'Pittsburgh']\n",
    "pitt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:18.004190Z",
     "start_time": "2021-08-26T22:30:17.053463Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Examining statistics for the new dataframe\n",
    "eda.report_df(pitt_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The dataset currently contains monthly sale price data as columns for each zip code. In order to be able to use the sale pricing, I will use a custom function provided as part of this project to convert the year/month column label into a new single column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:18.100367Z",
     "start_time": "2021-08-26T22:30:18.006189Z"
    }
   },
   "outputs": [],
   "source": [
    "def melt_data(df):\n",
    "    \"\"\"\n",
    "    Takes the zillow_data dataset in wide form or a subset of the zillow_dataset.  \n",
    "    Returns a long-form datetime dataframe with the datetime column names\n",
    "    as the index and the values as the 'values' column.\n",
    "    \n",
    "    If more than one row is passes in the wide-form dataset, the values column\n",
    "    will be the mean of the values from the datetime columns in all of the rows.\n",
    "    \n",
    "    Source: https://github.com/learn-co-curriculum/dsc-phase-4-project/blob/\n",
    "    main/time-series/starter_notebook.ipynb\n",
    "    \"\"\"\n",
    "    \n",
    "    melted = pd.melt(df, id_vars=['RegionName', 'RegionID', 'SizeRank','City',\n",
    "                                  'State', 'Metro', 'CountyName'],\n",
    "                     var_name='time')\n",
    "    melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "    melted = melted.dropna(subset=['value'])\n",
    "    \n",
    "    return melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:18.226462Z",
     "start_time": "2021-08-26T22:30:18.102173Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Melting the dataframe to move the dates from columns to new rows per zipcode\n",
    "pitt_melted = melt_data(pitt_df)\n",
    "pitt_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:18.335988Z",
     "start_time": "2021-08-26T22:30:18.229263Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirming conversion to \"datetime\" datatype\n",
    "pitt_melted['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:18.458448Z",
     "start_time": "2021-08-26T22:30:18.338958Z"
    }
   },
   "outputs": [],
   "source": [
    "## Selecting columns to keep for modeling\n",
    "keep = ['RegionName', 'time', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:18.569161Z",
     "start_time": "2021-08-26T22:30:18.462348Z"
    }
   },
   "outputs": [],
   "source": [
    "## Keeping only modeling-relevant data\n",
    "pitt_data = pitt_melted[keep]\n",
    "pitt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:18.709134Z",
     "start_time": "2021-08-26T22:30:18.571134Z"
    }
   },
   "outputs": [],
   "source": [
    "## Setting datetime index (required for modeling)\n",
    "pitt_data.set_index('time', inplace=True)\n",
    "pitt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> *The following code is adapted from code within [this notebook](https://github.com/flatiron-school/Online-DS-FT-022221-Cohort-Notes/blob/master/Phase_4/topic_37_intro_to_time_series/topic_37_intro_to_time_series_crime_v3-SG.ipynb) by James Irving, Ph.D.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:18.818191Z",
     "start_time": "2021-08-26T22:30:18.712136Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating list of unique zipcodes from the dataframe\n",
    "zipcodes = list(pitt_data['RegionName'].unique())\n",
    "zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:18.928473Z",
     "start_time": "2021-08-26T22:30:18.820197Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting first zipcode in list - datetime index and associated sell value\n",
    "test_code = zipcodes[0]\n",
    "test_zipcode_series = pitt_data.groupby('RegionName')\\\n",
    "                                .get_group(test_code)['value']\\\n",
    "                                                            .rename(test_code)\n",
    "test_zipcode_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:19.177712Z",
     "start_time": "2021-08-26T22:30:18.930475Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating a dictionary to store each zipcode and its timeseries data\n",
    "\n",
    "zipcodes_dict = {}\n",
    "\n",
    "for zipcode in zipcodes:\n",
    "    \n",
    "    ## Create the series for each zipcode\n",
    "    zipcode_series = pitt_data.groupby('RegionName')\\\n",
    "                                                .get_group(zipcode)['value']\\\n",
    "                                                            .rename(zipcode)\n",
    "    \n",
    "    ## Save in zipcode dictionary\n",
    "    zipcodes_dict[zipcode] = zipcode_series.resample('MS').asfreq()\n",
    "    \n",
    "## Display the keys\n",
    "zipcodes_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:19.286088Z",
     "start_time": "2021-08-26T22:30:19.179679Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirming all zip codes are present in dictionary\n",
    "list(zipcodes_dict.keys()) == zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:19.398091Z",
     "start_time": "2021-08-26T22:30:19.288099Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting values for one key:value pair\n",
    "zipcodes_dict[15206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:19.540086Z",
     "start_time": "2021-08-26T22:30:19.400095Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## reviewing full dataset for Pittsburgh\n",
    "zipcodes_df_full = pd.DataFrame(zipcodes_dict)\n",
    "zipcodes_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:19.665071Z",
     "start_time": "2021-08-26T22:30:19.542102Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Selecting data starting from 2008 onwards\n",
    "zipcodes_df = zipcodes_df_full.loc['2008':]\n",
    "zipcodes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T/T Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:19.759975Z",
     "start_time": "2021-08-26T22:30:19.667076Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Testing first zipcode from dictionary\n",
    "zipcode_val = zipcodes_df[15206].copy()\n",
    "zipcode_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:20.214515Z",
     "start_time": "2021-08-26T22:30:19.762008Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Visualizing first zipcode priot to split\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,4))\n",
    "ax = zipcode_val.plot()\n",
    "ax.legend()\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Sale Price ($)')\n",
    "ax.set_title(f'Train/Test Split for Zipcode {zipcode_val.name}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:20.634242Z",
     "start_time": "2021-08-26T22:30:20.216487Z"
    }
   },
   "outputs": [],
   "source": [
    "## Splitting Data\n",
    "\n",
    "tts_cutoff = round(zipcode_val.shape[0]*.85)\n",
    "train = zipcode_val.iloc[:tts_cutoff]\n",
    "test = zipcode_val.iloc[tts_cutoff:]\n",
    "\n",
    "## Plot\n",
    "fig, ax = plt.subplots(figsize = (12,4))\n",
    "ax = train.plot(label='Train')\n",
    "ax = test.plot(label='Test')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Price ($)')\n",
    "ax.set_title(f'Train/Test Split for Zipcode {zipcode_val.name}')\n",
    "ax.axvline(train.index[-1], linestyle=\":\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:21.052937Z",
     "start_time": "2021-08-26T22:30:20.636130Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Testing functionalized train/test split for reuse on other zipcodes\n",
    "train, test, _,_ = tsm.ts_split(zipcode_val, show_vis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:21.160963Z",
     "start_time": "2021-08-26T22:30:21.055933Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting training set\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:21.253743Z",
     "start_time": "2021-08-26T22:30:21.162925Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Inspecting testing set\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Stationarity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "> The following functions are adapted from [this notebook](https://github.com/flatiron-school/Online-DS-FT-022221-Cohort-Notes/blob/master/Phase_4/topic_37_intro_to_time_series/topic_37_intro_to_time_series_crime_v3-SG.ipynb) by James Irving, Ph.D.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Dickey Fuller Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:21.362920Z",
     "start_time": "2021-08-26T22:30:21.255800Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Performing Dickey-Fuller Test\n",
    "zipdf_results = tsa.stattools.adfuller(train)\n",
    "zipdf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:21.501957Z",
     "start_time": "2021-08-26T22:30:21.364918Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Creating a dictionary to store initial results\n",
    "index_label =[f'{train.name}']\n",
    "labels = ['Test Stat','P-Value','Number of Lags Used','Number of Obs. Used',\n",
    "        'Critical Thresholds', 'AIC Value']\n",
    "results_dict  = dict(zip(labels,zipdf_results))\n",
    "\n",
    "## Saving results to a dictionary and adding T/F for whether exceeds standard\n",
    "## p-value of .05 and if we fail to reject the null hypothesis or not.\n",
    "results_dict['p < .05'] = results_dict['P-Value']<.05\n",
    "results_dict['Stationary'] = results_dict['p < .05']\n",
    "\n",
    "## Creating DataFrame from dictionary\n",
    "if isinstance(index_label,str):\n",
    "    index_label = [index_label]\n",
    "results_dict = pd.DataFrame(results_dict,index=index_label)\n",
    "results_dict = results_dict[['Test Stat','P-Value','Number of Lags Used',\n",
    "                             'Number of Obs. Used','P-Value','p < .05',\n",
    "                             'Stationary']]\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:21.627995Z",
     "start_time": "2021-08-26T22:30:21.508957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Testing functionality\n",
    "tsm.adf_test(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Removing Trends, Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:22.094915Z",
     "start_time": "2021-08-26T22:30:21.632999Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Testing differenced data\n",
    "tz_diff = train.diff().dropna()\n",
    "print(\"|\",\"---\",f\"Zipcode {train.name}\",\"---\",\"|\",\"\\n\")\n",
    "print(tz_diff)\n",
    "print('\\n\\n',\"|\",\"----\"*5,f\"ADF Results for Zipcode {train.name}\",\"-----\"*6,\"|\")\n",
    "display(tsm.adf_test(tz_diff))\n",
    "\n",
    "print('\\n\\n','|',\"----\"*7,f\"Visualizing Difference Shift\",\"---\"*7,\"|\")\n",
    "fig, ax = plt.subplots()\n",
    "ax = tz_diff.plot(label='Post-Differencing')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Price ($)')\n",
    "ax.set_title(f'Difference Shift for Zipcode {train.name}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:22.531110Z",
     "start_time": "2021-08-26T22:30:22.096917Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diff_results = tsm.remove_trends(train, \"diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:22.938241Z",
     "start_time": "2021-08-26T22:30:22.533970Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_results = tsm.remove_trends(train, \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:23.341278Z",
     "start_time": "2021-08-26T22:30:22.940241Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rolling_results = tsm.remove_trends(train, \"rolling mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:23.744142Z",
     "start_time": "2021-08-26T22:30:23.343185Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ewm_results = tsm.remove_trends(train, \"EWM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:24.445576Z",
     "start_time": "2021-08-26T22:30:23.746135Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Seasonal Decomposition\n",
    "decomp = seasonal_decompose(train)\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:24.601063Z",
     "start_time": "2021-08-26T22:30:24.448549Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Creating Dataframe with seasonality test results\n",
    "\n",
    "test_results = []\n",
    "test_results.append(tsm.adf_test(train))\n",
    "\n",
    "decomp_dict = {\"trend\": decomp.trend,'seasonal': decomp.seasonal,\n",
    "               'residuals': decomp.resid}\n",
    " \n",
    "for trend, results in decomp_dict.items():\n",
    "\n",
    "    results = results.fillna(0)\n",
    "    res = tsm.adf_test(results)\n",
    "    test_results.append(res)\n",
    "\n",
    "## make into a df\n",
    "seasonality_df = pd.concat(test_results)\n",
    "seasonality_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ACF/PACF Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.070886Z",
     "start_time": "2021-08-26T22:30:24.603029Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsm.plot_acf_pacf(train, suptitle='ACF/PACF for Training Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA Modeling and Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.163422Z",
     "start_time": "2021-08-26T22:30:25.073835Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Using pmdarima's functions to pre-determine the best values for \n",
    "# ## differencing prior to running auto_arima\n",
    "\n",
    "# n_d = ndiffs(train)\n",
    "# n_d\n",
    "\n",
    "# n_D = nsdiffs(train, m=12)\n",
    "# n_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.257162Z",
     "start_time": "2021-08-26T22:30:25.165419Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Using auto_arima to determine best parameters for modeling\n",
    "# auto_model = pmd.auto_arima(train,start_p=0,start_q=0,d=n_d,\n",
    "#                             max_p=3,max_q=3,\n",
    "#                             max_P=3,max_Q=3, D=n_D,\n",
    "#                             start_P=0,start_Q=0,\n",
    "#                             m=12,\n",
    "#                             verbose=2)\n",
    "\n",
    "# display(auto_model.summary())\n",
    "# auto_model.plot_diagnostics(figsize= (12,9));\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.350809Z",
     "start_time": "2021-08-26T22:30:25.258065Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# best_model = tsa.SARIMAX(train,order=auto_model.order,\n",
    "#                          seasonal_order = auto_model.seasonal_order,\n",
    "#                          enforce_invertibility=False).fit()\n",
    "\n",
    "# ## Display Summary + Diagnostics\n",
    "# display(best_model.summary())\n",
    "# best_model.plot_diagnostics(figsize=(12,9));\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.443879Z",
     "start_time": "2021-08-26T22:30:25.353568Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Using get_forecast to generate forecasted data\n",
    "# forecast = best_model.get_forecast(steps=len(test))\n",
    "\n",
    "# ## Saving confidence intervals and predicted mean for future\n",
    "# forecast_df = forecast.conf_int()\n",
    "# forecast_df.columns = ['Lower CI','Upper CI']\n",
    "# forecast_df['Forecast'] = forecast.predicted_mean\n",
    "# forecast_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.537761Z",
     "start_time": "2021-08-26T22:30:25.446877Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Plotting training, test data and forecasted results\n",
    "# fig,ax = plt.subplots(figsize=(13,6))\n",
    "\n",
    "# last_n_lags=12*5         \n",
    "\n",
    "# train.iloc[-last_n_lags:].plot(label='Training Data')\n",
    "# test.plot(label='Test Data')\n",
    "\n",
    "# ## Plotting forecasted data and confidence intervals\n",
    "# forecast_df['Forecast'].plot(ax=ax,label='Forecast')\n",
    "# ax.fill_between(forecast_df.index,forecast_df['Lower CI'],\n",
    "#                 forecast_df['Upper CI'],color='b',alpha=0.4)\n",
    "\n",
    "# ax.set(xlabel='Time')\n",
    "# ax.set(ylabel='Sell Price ($)')\n",
    "# ax.set_title('Data and Forecasted Data')\n",
    "# ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.630492Z",
     "start_time": "2021-08-26T22:30:25.539762Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = tsm.plot_forecast_ttf(train=train, test=test,\n",
    "#                                 forecast_df = forecast_df, n_yrs_past=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Save `conf_int`, `predicted_mean` - 4cDF\n",
    ">\n",
    ">\n",
    "> Plot Tr, Te, 4cDF\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.723334Z",
     "start_time": "2021-08-26T22:30:25.631843Z"
    }
   },
   "outputs": [],
   "source": [
    "# best_model = tsa.SARIMAX(zipcode_val,order=auto_model.order,\n",
    "#                          seasonal_order = auto_model.seasonal_order,\n",
    "#                          enforce_invertibility=False).fit()\n",
    "\n",
    "# display(best_model.summary())\n",
    "# best_model.plot_diagnostics(figsize=(12,9));\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.818506Z",
     "start_time": "2021-08-26T22:30:25.725231Z"
    }
   },
   "outputs": [],
   "source": [
    "# auto_model_best, best_model_overall = tsm.create_best_model(zipcode_val, m=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:25.911620Z",
     "start_time": "2021-08-26T22:30:25.821292Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Using get_forecast to generate forecasted data\n",
    "# forecast = best_model.get_forecast(steps=24)\n",
    "\n",
    "# ## Saving confidence intervals and predicted mean for future\n",
    "# forecast_df = forecast.conf_int()\n",
    "# forecast_df.columns = ['Lower CI','Upper CI']\n",
    "# forecast_df['Forecast'] = forecast.predicted_mean\n",
    "# forecast_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:26.005319Z",
     "start_time": "2021-08-26T22:30:25.914621Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Plotting training, test data and forecasted results\n",
    "# fig,ax = plt.subplots(figsize=(13,6))\n",
    "\n",
    "# zipcode_val.plot(label='Training Data')\n",
    "\n",
    "# ## Plotting forecasted data and confidence intervals\n",
    "# forecast_df['Forecast'].plot(ax=ax,label='Forecast')\n",
    "# ax.fill_between(forecast_df.index,forecast_df['Lower CI'],\n",
    "#                 forecast_df['Upper CI'],color='b',alpha=0.4)\n",
    "\n",
    "# ax.set(xlabel='Time')\n",
    "# ax.set(ylabel='Sale Price ($)')\n",
    "# ax.set_title('Data and Forecasted Data')\n",
    "# ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:26.099158Z",
     "start_time": "2021-08-26T22:30:26.007291Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# forecast_overall = tsm.forecast_and_ci(best_model_overall, n_yrs_future = 2)\n",
    "# forecast_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:26.224156Z",
     "start_time": "2021-08-26T22:30:26.101157Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = tsm.plot_forecast_final(zipcode_val, forecast_overall)\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:26.317158Z",
     "start_time": "2021-08-26T22:30:26.226157Z"
    }
   },
   "outputs": [],
   "source": [
    "# investment_cost = forecast_df.iloc[0,2]\n",
    "# investment_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:26.412423Z",
     "start_time": "2021-08-26T22:30:26.320161Z"
    }
   },
   "outputs": [],
   "source": [
    "# roi_df = (forecast_df - investment_cost)/investment_cost*100\n",
    "# roi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:26.552126Z",
     "start_time": "2021-08-26T22:30:26.414450Z"
    }
   },
   "outputs": [],
   "source": [
    "# roi_final = roi_df.iloc[-1]\n",
    "# roi_final.name = zipcode_val.name.astype('str')\n",
    "# roi_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:26.660272Z",
     "start_time": "2021-08-26T22:30:26.554112Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(roi_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:28.658364Z",
     "start_time": "2021-08-26T22:30:26.663272Z"
    }
   },
   "outputs": [],
   "source": [
    "_, roi_df, _, _, _, _, _, _, _, _ = tsm.ts_modeling_workflow(zipcodes_df, 15206, threshold=.85)\n",
    "roi_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Based on my model, the ROI for the zipcode 15206 would be an average of 65.48%. However, the results may fall anywhere between 19.05% - 111.91%.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionalizing Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:31.001117Z",
     "start_time": "2021-08-26T22:30:28.661227Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Testing full workflow function\n",
    "\n",
    "fcst_full, roi_df, split_vis, fcst_len, sum_train, diag_train,sum_full,\\\n",
    "    diag_full, training_frcst,final_frcst = tsm.ts_modeling_workflow\\\n",
    "            (dataframe = zipcodes_df, zipcode = 15206, m=12, show_vis = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Remaining Zip Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Now I will process the remaining zip codes via a for loop to process them through the work flow. As part of the work flow, I will review each model's performance visualizations to ensure it is appropriate for forecasting.\n",
    ">\n",
    ">\n",
    ">I will save the results to the overall dictionary for my final review and interpretation.\n",
    "\n",
    "---\n",
    "\n",
    "> ***Special Note:*** Before looping through the entirety of the zip codes, I remove the zip code \"15210\" and process it separately.\n",
    ">\n",
    ">\n",
    "> This is due to significant delays in running the loop (increasing loop runtime from 1.5 min to upwards of 10 minutes). The issue stems from errors during the modeling process when using the default train/test split threshold of .85.\n",
    ">\n",
    ">\n",
    "> To resolve the issue, I run the zip code through the same process as the loop and save the results to the overall dictionary.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:30:31.096431Z",
     "start_time": "2021-08-26T22:30:31.003085Z"
    }
   },
   "outputs": [],
   "source": [
    "## Separating the 15210 zipcode to prevent runtime delays\n",
    "shorter_list = list(zipcodes_df.columns)\n",
    "shorter_list.remove(15210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:04.411769Z",
     "start_time": "2021-08-26T22:30:31.098431Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Creating dictionary and storing all zipcodes and results\n",
    "overall_results = {}\n",
    "\n",
    "for i, zipcode in enumerate(shorter_list):\n",
    "    \n",
    "    print('|',\"---\"*10,f'Zipcode {zipcode}',\"---\"*10,'|\\n')\n",
    "    print(f'--> Zipcode {i+1} of {len(shorter_list)}')\n",
    "    \n",
    "    ## Create temporary dictionaries\n",
    "    zip_tsa_results = {}\n",
    "    metrics = {}\n",
    "    forecast_vis = {}\n",
    "    \n",
    "    ## Use functionalized workflow to obtain results\n",
    "    forecast_full, roi_df, split_vis, forecast_length, summary_train,\\\n",
    "        diag_train, summary_full, diag_full, training_frcst,final_frcst =\\\n",
    "        tsm.ts_modeling_workflow(dataframe = zipcodes_df, threshold = .85,\n",
    "                                 zipcode = zipcode, m=12, show_vis = True,\n",
    "                                 figsize=(12,4))\n",
    "    \n",
    "    ## Save results to temporary dictionaries\n",
    "    metrics['train'] = [summary_train, diag_train]\n",
    "    metrics['full'] = [summary_full, diag_full]\n",
    "    \n",
    "    forecast_vis['train'] = training_frcst\n",
    "    forecast_vis['full'] = final_frcst\n",
    "    forecast_vis['split'] = split_vis\n",
    "    \n",
    "    zip_tsa_results['num_yrs_forecast'] = forecast_length\n",
    "    zip_tsa_results['forecasted_prices'] = forecast_full\n",
    "    zip_tsa_results['roi'] = roi_df\n",
    "    zip_tsa_results['model_metrics'] = metrics\n",
    "    zip_tsa_results['model_visuals'] = forecast_vis\n",
    "    \n",
    "    ## Save final temporary dictionary to overall dictionary\n",
    "    overall_results[zipcode] = zip_tsa_results\n",
    "    \n",
    "    print(f'--> Zipcode {i+1} of {len(shorter_list)}')\n",
    "    print('|',\"---\"*5,f'Completed: {zipcode}',\"---\"*5,'|\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:16.972834Z",
     "start_time": "2021-08-26T22:32:04.414758Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Processing zipcode 15210 separately\n",
    "overall_results[15210] = tsm.make_dict(zipcodes_df, 15210, .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting Dictionary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:17.081554Z",
     "start_time": "2021-08-26T22:32:16.974557Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_results[15206].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:17.190607Z",
     "start_time": "2021-08-26T22:32:17.083551Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Inspecting \"forecasted prices\" key\n",
    "overall_results[15206]['forecasted_prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:17.299133Z",
     "start_time": "2021-08-26T22:32:17.192375Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Inspecting \"roi\" key\n",
    "overall_results[15206]['roi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:17.753810Z",
     "start_time": "2021-08-26T22:32:17.301125Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reviewing training model metrics\n",
    "display(overall_results[15206]['model_metrics']['train'][0])\n",
    "display(overall_results[15206]['model_metrics']['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:18.364848Z",
     "start_time": "2021-08-26T22:32:17.755611Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reviewing model forecasts\n",
    "display(overall_results[15206]['model_visuals']['split'])\n",
    "display(overall_results[15206]['model_visuals']['train'])\n",
    "display(overall_results[15206]['model_visuals']['full'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosing Zip Code Forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> After generating the forecast results for all of the zip codes, I reviewed the validation results for each zip code.\n",
    ">\n",
    ">\n",
    "> Certain zip codes showed the actual sale price trend lines getting too close to the upper/lower confidence intervals. Several models missed the trends entirely, resulting in the actual data exceeding the confidence interval.\n",
    ">\n",
    ">\n",
    "> **I will readjust the train/test threshold for the selected zip codes to address these issues.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Groups for Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:18.459052Z",
     "start_time": "2021-08-26T22:32:18.366847Z"
    }
   },
   "outputs": [],
   "source": [
    "## Adding .025 to threshold\n",
    "thresh_a025 = [15217,15213,15216]\n",
    "\n",
    "## Subtracting .05 from threshold\n",
    "thresh_s05 = [15243]\n",
    "\n",
    "## Subtracting .075 from threshold\n",
    "thresh_s075 = [15210, 15207, 15204]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review - `'thresh_a025'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:19.686696Z",
     "start_time": "2021-08-26T22:32:18.461531Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Inspecting split and validation visuals for missed trends\n",
    "\n",
    "for code in thresh_a025:\n",
    "    print(\"\\n|\",\"--\"*24,f\"Visualizations for {code}\",\"--\"*24,\"|\\n\")\n",
    "    display(overall_results[code]['model_visuals']['split'])\n",
    "    display(overall_results[code]['model_visuals']['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation - `'thresh_a025'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> For these zip codes, I see that the train/test split threshold slightly missed a trend in the data, causing the actual results to approach one of the limits of the threshold too closely.\n",
    ">\n",
    ">\n",
    "> I will test whether **increasing the threshold slightly would capture more of the trend**, bringing my forecast data closer to the test data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review - `'thresh_s05'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:20.293370Z",
     "start_time": "2021-08-26T22:32:19.688695Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Inspecting split and validation visuals for missed trends\n",
    "\n",
    "for code in thresh_s05:\n",
    "    print(\"\\n|\",\"--\"*24,f\"Visualizations for {code}\",\"--\"*24,\"|\\n\")\n",
    "    display(overall_results[code]['model_visuals']['split'])\n",
    "    display(overall_results[code]['model_visuals']['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation - `'thresh_s05'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Similar to the prior zipcodes, these zipcodes missed the trend as well. However, it seems that the trend may be *behind* the threshold.\n",
    ">\n",
    ">\n",
    "> I will test whether **decreasing the threshold by .05 would capture more of the trend.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review - `'thresh_s075'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:21.741959Z",
     "start_time": "2021-08-26T22:32:20.296372Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Inspecting split and validation visuals for missed trends\n",
    "\n",
    "for i, zipcode in enumerate(thresh_s075):\n",
    "    \n",
    "    print('|',\"---\"*10,f'Zipcode {zipcode}',\"---\"*10,'|\\n')\n",
    "    print(f'--> Zipcode {i+1} of {len(thresh_s075)}\\n')\n",
    "    \n",
    "    ## Reviewing training model metrics\n",
    "    \n",
    "    print('|',\"---\"*5,'Model Visualizations',\"---\"*5,'|\\n')\n",
    "    display(overall_results[zipcode]['model_visuals']['split'])\n",
    "    display(overall_results[zipcode]['model_visuals']['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation - `'thresh_s075'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **These zipcodes missed the trends significantly as well, with forecasts exceeding the confidence intervals.** The trends may be further behind the threshold, requiring more of a reduction in the threshold.\n",
    ">\n",
    ">\n",
    "> I will test whether **decreasing the threshold by .075 would capture more of the trend.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review - Zipcode `15226`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> During my review, I noticed there was a sharp increase in the trend line for the zip code 15226, causing my model to mis-forecast the sale prices.\n",
    ">\n",
    ">\n",
    "> **In order to address this error, I would need to increase my threshold an additional 5%.** This decision would be problematic, however, as it would limit the scope of this, and all other forecasts, to a one-year scope.\n",
    ">\n",
    ">\n",
    "> **Instead of limiting all of my forecasts due to this single zip code, I will leave the model results at the .85 threshold.** \n",
    ">\n",
    ">\n",
    "> For exploratory purposes, I will visualize the impact of the change to a .90 threshold. However, **these results will not be included in my final results.**\n",
    ">\n",
    ">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:24.373500Z",
     "start_time": "2021-08-26T22:32:21.743974Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## EDA modeling of the 15226 zip code at a .9 threshold for train/test split\n",
    "\n",
    "tsm.ts_modeling_workflow(zipcodes_df, 15226,threshold = .9, show_vis = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation  - Zip Code `15226`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> As expected, increasing the threshold did increase the accuracy of the trend for the 15226 zip code. However, this change would limit the forecasts of the other zip codes by nearly 6 months. As this is only one zipcode, I will leave it's threshold at .85 to maintain the forecasts for the others.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating - `'thresh_a025'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:32.846775Z",
     "start_time": "2021-08-26T22:32:24.375501Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, zipcode in enumerate(thresh_a025):\n",
    "    \n",
    "    print('|',\"---\"*10,f'Zipcode {zipcode}',\"---\"*10,'|\\n')\n",
    "    print(f'--> Zipcode {i+1} of {len(thresh_a025)}')\n",
    "    \n",
    "   \n",
    "    overall_results[zipcode] = tsm.make_dict(zipcodes_df, zipcode,\n",
    "                                             threshold = .875, show_vis = True)\n",
    "    \n",
    "    print('|',\"---\"*3,f'Completed: {zipcode}, {i+1} of {len(thresh_a025)}',\"---\"*3,'|\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Changes  - `thresh_a025`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The slight increase to the threshold for these zipcodes brought the forecasts much closer to the test values, in most cases making them nearly the same as the test data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating `'thresh_s05'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:34.818497Z",
     "start_time": "2021-08-26T22:32:32.849620Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, zipcode in enumerate(thresh_s05):\n",
    "    \n",
    "    print('|',\"---\"*10,f'Zipcode {zipcode}',\"---\"*10,'|\\n')\n",
    "    print(f'--> Zipcode {i+1} of {len(thresh_s05)}')\n",
    "    \n",
    "   \n",
    "    overall_results[zipcode] = tsm.make_dict(zipcodes_df, zipcode,\n",
    "                                             threshold = .8, show_vis = True)\n",
    "\n",
    "    print('|',\"---\"*3,f'Completed: {zipcode}, {i+1} of {len(thresh_s05)}',\n",
    "          \"---\"*3,'|\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Changes  - `thresh_s05`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The decrease of .05 in my threshold improved my forecasts for 15243. However, it seems my forecast for 15226 could still improve.\n",
    ">\n",
    ">\n",
    "> I will need to change the threshold again for 15226 to increase the accuracy of my forecast.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating `'thresh_s075'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:32:53.782638Z",
     "start_time": "2021-08-26T22:32:34.820503Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, zipcode in enumerate(thresh_s075):\n",
    "    \n",
    "    print('|',\"---\"*10,f'Zipcode {zipcode}',\"---\"*10,'|\\n')\n",
    "    print(f'--> Zipcode {i+1} of {len(thresh_s075)}')\n",
    "    \n",
    "   \n",
    "    overall_results[zipcode] = tsm.make_dict(zipcodes_df, zipcode,\n",
    "                                             threshold = .775, show_vis = True)\n",
    "    \n",
    "    print('|',\"---\"*3,f'Completed: {zipcode}, {i+1} of {len(thresh_s075)}',\n",
    "          \"---\"*3,'|\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Changes  - `thresh_s075`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The decrease of .075 in my threshold improved my forecasts for 15207, but they still have room for improvement. However, this threshold is still showing poor performance for 15210 and 15204.\n",
    ">\n",
    ">\n",
    "> I will change the threshold again for these zip codes to see if a larger decrease would improve the accuracy further.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating `thresh_s075` - .725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:13.898505Z",
     "start_time": "2021-08-26T22:32:53.784639Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Decreasing threshold to .725\n",
    "\n",
    "for i, zipcode in enumerate(thresh_s075):\n",
    "    print('|',\"---\"*10,f'Zipcode {zipcode}',\"---\"*10,'|\\n')\n",
    "    print(f'--> Zipcode {i+1} of {len(thresh_s075)}')\n",
    "    \n",
    "   \n",
    "    overall_results[zipcode] = tsm.make_dict(zipcodes_df, zipcode,\n",
    "                                             threshold = .725, show_vis = True)\n",
    "    \n",
    "    print('|',\"---\"*3,f'Completed: {zipcode}, {i+1} of {len(thresh_s075)}',\n",
    "          \"---\"*3,'|\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Changes v2  - `thresh_s075`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Bringing the threshold down to .725 from .85 brought the zip code 15207 within its confidence interval. However, zip codes 15204 and 15210 both have unstable trend lines in the training and test data, making it hard for the model to predict accurate results.\n",
    ">\n",
    ">\n",
    "> I will accept these results with the understanding that the forecast for zip codes 15204 and 15210 will be inaccurate.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Now that I collected all of the results for each zip code, I will calculate and save the return on investment (ROI) values for each zip code.\n",
    ">\n",
    ">\n",
    "> I will determine my final recommendations based on the ROI results as well as using the lower confidence interval to determine the risk of each zip code.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:13.991159Z",
     "start_time": "2021-08-26T22:33:13.900468Z"
    }
   },
   "outputs": [],
   "source": [
    "## Identifying keys for each zip code\n",
    "overall_results[15206].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:14.083660Z",
     "start_time": "2021-08-26T22:33:13.993413Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting ROI dictionary\n",
    "overall_results[15206]['roi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:14.208606Z",
     "start_time": "2021-08-26T22:33:14.085670Z"
    }
   },
   "outputs": [],
   "source": [
    "## Calculating number of months used in each forecast\n",
    "roi_len = []\n",
    "\n",
    "for zipcode, data in overall_results.items():\n",
    "    roi_len.append(len(data['roi']))\n",
    "    \n",
    "roi_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:14.317596Z",
     "start_time": "2021-08-26T22:33:14.211609Z"
    }
   },
   "outputs": [],
   "source": [
    "## Determining minimum number of months for comparisons\n",
    "roi_idx = min(roi_len)\n",
    "roi_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:14.426537Z",
     "start_time": "2021-08-26T22:33:14.319564Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirming indexing works as expected\n",
    "overall_results[15206]['roi'].iloc[roi_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:14.552546Z",
     "start_time": "2021-08-26T22:33:14.428529Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Collecting forecasted ROI and confidence intervals\n",
    "roi_test = []\n",
    "\n",
    "for zipcode, data in overall_results.items():\n",
    "    roi_test.append(data['roi'].iloc[roi_idx-1].rename(zipcode).to_frame().T)\n",
    "    \n",
    "roi_df = pd.concat(roi_test)\n",
    "\n",
    "roi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:14.722542Z",
     "start_time": "2021-08-26T22:33:14.555545Z"
    }
   },
   "outputs": [],
   "source": [
    "## Sorting for zip codes with highest ROI\n",
    "best_roi_df = roi_df.sort_values('Forecast', ascending=False)\n",
    "best_roi_df.style.background_gradient(subset=['Forecast'],\n",
    "                                  cmap='RdYlGn')\\\n",
    "                                    .set_caption('Zipcodes by Forecasted ROI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:14.830536Z",
     "start_time": "2021-08-26T22:33:14.724542Z"
    }
   },
   "outputs": [],
   "source": [
    "best_roi_df.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:14.954477Z",
     "start_time": "2021-08-26T22:33:14.832465Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Sorting for riskiest zipcodes\n",
    "risk_df = roi_df.sort_values('Lower CI')\n",
    "risk_df.style.background_gradient(subset=['Lower CI'],\n",
    "                                  cmap='RdYlGn').set_caption('Zipcodes by Risk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T22:33:20.866621Z",
     "start_time": "2021-08-26T22:33:14.956501Z"
    }
   },
   "outputs": [],
   "source": [
    "## Saving forecast figures in notebook\n",
    "import os\n",
    "fig_folder = \"./img/\"\n",
    "os.makedirs(fig_folder,exist_ok=True)\n",
    "\n",
    "for zipcode in overall_results:\n",
    "    fig = overall_results[zipcode]['model_visuals']['full']\n",
    "    fig.savefig(f\"{fig_folder}forecast_for_{zipcode}.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> My forecasts are limited to a 16-month viewpoint (based on the size of the data used for testing purposes).\n",
    "\n",
    "---\n",
    "\n",
    "> I would recommend short-term buyers to **focus on the following areas:**\n",
    ">  * East Liberty **(zip code 15206, ROI: 42.7%)**\n",
    ">  * Lawrenceville **(15201, ROI: 38.8)**\n",
    ">  * North Shore/Brighton Heights **(15212, ROI: 28.9%)**\n",
    "\n",
    "---\n",
    "\n",
    "> I would recommend for short-term buyers to **avoid the following areas due to high risk of losing money:**\n",
    ">  * Shadyside **(15232, 39.3% risk)**\n",
    ">  * Oakland/North Oakland **(15213, 34.2% risk)**\n",
    ">  * Perry South/Northview Heights/Summer Hill **(15214, 27.4%)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> * Comparing forecasts to actualized sales using updated data from Zillow.\n",
    "> * Exploring a larger range of values for the splitting threshold.\n",
    "> * Identifying and adding exogenous data to support forecasts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "331px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
